{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7bd953d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initiate libraries\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "# import open3d as o3d\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoImageProcessor, AutoModelForDepthEstimation, pipeline\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ba653b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1. Read project modules\n",
    "\n",
    "from depthanythingv1 import *\n",
    "from openback import *\n",
    "from watertight import *\n",
    "from merge_meshes import *\n",
    "from scale_meshes import *\n",
    "from utils_colors import *\n",
    "from utils_pointcloud import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65ed6ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initiate directories\n",
    "\n",
    "# Directory with input images\n",
    "rgb_dir = \"rgb_dir\"\n",
    "\n",
    "# Directory to save .npy depth maps\n",
    "depth_dir = \"depth_dir\"\n",
    "os.makedirs(depth_dir, exist_ok=True)\n",
    "\n",
    "# Directory to save colored depth maps\n",
    "depth_colored_dir = \"depth_colored_dir\"\n",
    "os.makedirs(depth_colored_dir, exist_ok=True)\n",
    "\n",
    "# Directory to save black-and-white depth maps\n",
    "depth_bw_dir = \"depth_bw_dir\"\n",
    "os.makedirs(depth_bw_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d8e2bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1. Choose colormap-scheme for colored depth map\n",
    "colormap_scheme = \"inferno\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e229502f",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot write mode F as PNG",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Documents\\Studium\\Masters\\7. Thesis\\Code\\full_workflow\\.venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:1370\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(im, fp, filename, chunk, save_all)\u001b[39m\n\u001b[32m   1369\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1370\u001b[39m     rawmode, bit_depth, color_type = \u001b[43m_OUTMODES\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutmode\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyError\u001b[39m: 'F'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 3. Depth Estimation with DepthAnything V1\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Run depth estimation algorithm\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mbatch_process_depth_estimation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrgb_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrgb_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_npy_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdepth_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_bw_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdepth_bw_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_colored_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdepth_colored_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolormap_scheme\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolormap_scheme\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Documents\\Studium\\Masters\\7. Thesis\\Code\\full_workflow\\depthanythingv1.py:84\u001b[39m, in \u001b[36mbatch_process_depth_estimation\u001b[39m\u001b[34m(rgb_dir, depth_npy_dir, depth_colored_dir, depth_bw_dir, colormap_scheme)\u001b[39m\n\u001b[32m     80\u001b[39m depth_bw = (depth_norm.cpu().numpy() * \u001b[32m255\u001b[39m)\n\u001b[32m     82\u001b[39m bw_path = os.path.join(depth_bw_dir, root + \u001b[33m\"\u001b[39m\u001b[33m_depth_bw.png\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[43mImage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth_bw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbw_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[38;5;66;03m# Saves colored depth map\u001b[39;00m\n\u001b[32m     87\u001b[39m colormap = plt.colormaps[colormap_scheme]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Documents\\Studium\\Masters\\7. Thesis\\Code\\full_workflow\\.venv\\Lib\\site-packages\\PIL\\Image.py:2571\u001b[39m, in \u001b[36mImage.save\u001b[39m\u001b[34m(self, fp, format, **params)\u001b[39m\n\u001b[32m   2568\u001b[39m     fp = cast(IO[\u001b[38;5;28mbytes\u001b[39m], fp)\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2571\u001b[39m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   2573\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Documents\\Studium\\Masters\\7. Thesis\\Code\\full_workflow\\.venv\\Lib\\site-packages\\PIL\\PngImagePlugin.py:1373\u001b[39m, in \u001b[36m_save\u001b[39m\u001b[34m(im, fp, filename, chunk, save_all)\u001b[39m\n\u001b[32m   1371\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1372\u001b[39m     msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcannot write mode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m as PNG\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1373\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1374\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m outmode == \u001b[33m\"\u001b[39m\u001b[33mI\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1375\u001b[39m     deprecate(\u001b[33m\"\u001b[39m\u001b[33mSaving I mode images as PNG\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m13\u001b[39m, stacklevel=\u001b[32m4\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: cannot write mode F as PNG"
     ]
    }
   ],
   "source": [
    "# 3. Depth Estimation with DepthAnything V1\n",
    "\n",
    "# Run depth estimation algorithm\n",
    "\n",
    "batch_process_depth_estimation(rgb_dir=rgb_dir, depth_npy_dir=depth_dir, depth_bw_dir=depth_bw_dir, depth_colored_dir=depth_colored_dir, colormap_scheme=colormap_scheme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32bde949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# 3. Depth Estimation with DepthAnything V1\n",
    "\n",
    "# 3.1. Initiatze checkpoints\n",
    "\n",
    "checkpoints = [\n",
    "    \"Intel/zoedepth-nyu-kitti\",\n",
    "    \"LiheYoung/depth-anything-large-hf\",\n",
    "    \"jingheya/lotus-depth-g-v1-0\",   \n",
    "    \"tencent/DepthCrafter\"\n",
    "    ]\n",
    "\n",
    "checkpoint = \"LiheYoung/depth-anything-large-hf\"\n",
    "\n",
    "# 3.2. Load models\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)\n",
    "model = AutoModelForDepthEstimation.from_pretrained(checkpoint).to(\"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "290f1271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved depth_dir\\sb1-obv_depth.npy and depth_bw_dir\\sb1-obv_depth.png\n",
      "Saved depth_dir\\sb1-rev_depth.npy and depth_bw_dir\\sb1-rev_depth.png\n",
      "Saved depth_dir\\sb2-obv_depth.npy and depth_bw_dir\\sb2-obv_depth.png\n",
      "Saved depth_dir\\sb2-rev_depth.npy and depth_bw_dir\\sb2-rev_depth.png\n"
     ]
    }
   ],
   "source": [
    "# 3.3. Run depth estimation algorithm\n",
    "\n",
    "for filename in sorted(os.listdir(rgb_dir)):\n",
    "    if not filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        continue\n",
    "\n",
    "    base = filename.rsplit(\".\", 1)[0]\n",
    "\n",
    "    img_path = os.path.join(rgb_dir, filename)\n",
    "\n",
    "    image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    # Preprocesses\n",
    "    inputs = image_processor(images=image, return_tensors=\"pt\")\n",
    "\n",
    "    # Predicts\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Post-processes\n",
    "    post_processed_output = image_processor.post_process_depth_estimation(\n",
    "        outputs,\n",
    "        target_sizes=[(image.height, image.width)]\n",
    "    )\n",
    "\n",
    "    predicted_depth = post_processed_output[0][\"predicted_depth\"]\n",
    "\n",
    "    # Saves .npy\n",
    "    npy_path = os.path.join(depth_dir, base + \"_depth.npy\")\n",
    "    np.save(npy_path, predicted_depth.cpu().numpy())\n",
    "\n",
    "    # Saves grayscale depth .png\n",
    "    depth_norm = (predicted_depth - predicted_depth.min()) / (predicted_depth.max() - predicted_depth.min())\n",
    "    depth = (depth_norm.cpu().numpy() * 255).astype(\"uint8\")\n",
    "\n",
    "    gray_path = os.path.join(depth_bw_dir, base + \"_depth.png\")\n",
    "\n",
    "    Image.fromarray(depth).save(gray_path)\n",
    "\n",
    "    # Saves colored depth .png\n",
    "\n",
    "    colormap = plt.colormaps[\"inferno\"]\n",
    "\n",
    "    depth_colored = colormap(depth_norm.cpu().numpy())\n",
    "\n",
    "    depth_colored = (depth_colored[:,:,:3] * 255).astype(\"uint8\")\n",
    "\n",
    "    colored_path = os.path.join(depth_colored_dir, base + \"_depth_colored.png\")\n",
    "\n",
    "    Image.fromarray(depth_colored).save(colored_path)\n",
    "\n",
    "    print(f\"Saved {npy_path} and {gray_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e58e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 3D model creation\n",
    "\n",
    "# 4.1. Non-watertight models\n",
    "out_dir_openback = \"3d_models_openback\"\n",
    "os.makedirs(out_dir_openback, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "pixel_size = 1.0 # recommended: 1.0\n",
    "relief_scale = 7.0 # recommended: 6.0 - 9.0\n",
    "poisson_depth = 9 # recommended: 8-9\n",
    "output_format = \"obj\" # recommended: \"obj\", \"ply\"\n",
    "\n",
    "batch_process_openback(depth_dir, rgb_dir, out_dir_openback, output_format=output_format, pixel_size=pixel_size, relief_scale=relief_scale, poisson_depth=poisson_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf365aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2. Watertight models\n",
    "out_dir_watertight = \"3d_models_watertight\"\n",
    "os.makedirs(out_dir_watertight, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "pixel_size = 1.0 # recommended: 1.0\n",
    "relief_scale = 7.0 # recommended: 6.0 - 9.0\n",
    "poisson_depth = 9 # recommended: 8-9\n",
    "output_format = \"obj\" # recommended: \"obj\", \"ply\"\n",
    "\n",
    "batch_process_watertight(depth_dir, rgb_dir, out_dir_watertight, output_format=output_format, pixel_size=pixel_size, relief_scale=relief_scale, poisson_depth=poisson_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634d356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3. Merged models\n",
    "input_dir = \"3d_models_openback\"\n",
    "output_dir_merged = \"3d_models_merged\"\n",
    "os.makedirs(output_dir_merged, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "gap_factor = 0.0 # recommended: 0.0\n",
    "scale = True\n",
    "scale_factor = 0.25\n",
    "\n",
    "batch_process_merge(input_dir, output_dir, gap_factor=gap_factor, scale=scale, scale_factor=scale_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cec4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4. Scale models\n",
    "input_dir_to_scale = \"3d_models_merged\"\n",
    "output_dir_scaled = \"3d_models_scaled\"\n",
    "\n",
    "# Parameters\n",
    "scale_factor = 0.02\n",
    "\n",
    "batch_scale_models(input_dir_to_scale, output_dir_scaled, scale_factor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
